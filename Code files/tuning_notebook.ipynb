{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cell_id": "bfb80f423ade45e79415dfe09ae790b7",
    "deepnote_cell_type": "code",
    "execution_context_id": "e7e3c053-c9c8-4c12-ac24-9878d7e18268",
    "execution_millis": 231,
    "execution_start": 1734366700085,
    "source_hash": "c264d352"
   },
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "import numpy as np\n",
    "from ioh import get_problem, logger, ProblemClass\n",
    "from GA import s4018907_s4168216_GA, create_problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "cell_id": "62376443af8a4a6c8036929fe84064fb",
    "deepnote_cell_type": "code",
    "execution_context_id": "e7e3c053-c9c8-4c12-ac24-9878d7e18268",
    "execution_millis": 0,
    "execution_start": 1734366700405,
    "source_hash": "bb55d451"
   },
   "outputs": [],
   "source": [
    "from typing import Tuple \n",
    "import numpy as np\n",
    "import ioh\n",
    "from ioh import get_problem, logger, ProblemClass\n",
    "\n",
    "def n_crossover(p1, p2, size, n=2, crossover_rate = 0.5):\n",
    "\n",
    "    if np.random.rand() > crossover_rate:\n",
    "        # If not, just return the parents as children (no crossover)\n",
    "        return p1, p2\n",
    "\n",
    "    split_positions = sorted(np.random.choice(range(size), n, replace=False))\n",
    "    c1 = []\n",
    "    c2 = []\n",
    "    subarrays_p1 = np.split(p1, split_positions)\n",
    "    subarrays_p2 = np.split(p2, split_positions)\n",
    "    \n",
    "    for i in range(len(subarrays_p1)):\n",
    "        if (i % 2 == 0):\n",
    "            for j in range(len(subarrays_p1[i])):\n",
    "                c1.append(subarrays_p1[i][j])\n",
    "                c2.append(subarrays_p2[i][j])\n",
    "        else: \n",
    "            for j in range(len(subarrays_p2[i])):\n",
    "                c1.append(subarrays_p2[i][j])\n",
    "                c2.append(subarrays_p1[i][j])\n",
    "    return c1,c2\n",
    "\n",
    "def mating_selection(population, pop_fitness):\n",
    "    f_min = min(pop_fitness)\n",
    "    f_sum = sum(pop_fitness) - (f_min - 0.001) * len(pop_fitness)\n",
    "    \n",
    "    rw = [(pop_fitness[0] - f_min + 0.001)/f_sum]\n",
    "    for i in range(1,len(pop_fitness)):\n",
    "        rw.append(rw[i-1] + (pop_fitness[i] - f_min + 0.001) / f_sum)\n",
    "    \n",
    "    select_parent = []\n",
    "    for i in range(2) :\n",
    "        r = np.random.uniform(0,1)\n",
    "        index = 0\n",
    "        # print(rw,r)\n",
    "        while(r > rw[index]) :\n",
    "            index = index + 1\n",
    "        \n",
    "        select_parent.append(population[index].copy())\n",
    "    return select_parent\n",
    "\n",
    "def mutate(c, mutation_rate):\n",
    "    ind_length = len(c)\n",
    "    for j in range(ind_length):  \n",
    "        if np.random.uniform(0, 1) < mutation_rate:\n",
    "            swap_idx = np.random.randint(0, ind_length)\n",
    "            c[j], c[swap_idx] = c[swap_idx], c[j]  # Swap mutation\n",
    "\n",
    "    return c\n",
    "\n",
    "def s4018907_s4168216_GA(problem: ioh.problem.PBO, init_pop_size: int, mutation_rate: float, crossover_rate: float, budget: int) -> None:\n",
    "    # initial_pop = ... make sure you randomly create the first population\n",
    "    #initial_pop_size = pop_size\n",
    "    # mutation_rate = \n",
    "    #crossover_rate = 0.5\n",
    "    population = []\n",
    "    pop_fitness = []\n",
    "\n",
    "    for i in range(init_pop_size):\n",
    "        # Initialization\n",
    "        population.append(np.random.randint(2, size = problem.meta_data.n_variables))\n",
    "        pop_fitness.append(problem(population[i]))\n",
    "\n",
    "    # `problem.state.evaluations` counts the number of function evaluation automatically,\n",
    "    # which is incremented by 1 whenever you call `problem(x)`.\n",
    "    # You could also maintain a counter of function evaluations if you prefer.\n",
    "    while problem.state.evaluations < budget:\n",
    "        parents = mating_selection(population, pop_fitness)\n",
    "        p1 = parents[0]\n",
    "        p2 = parents[1]\n",
    "        c1, c2 = n_crossover(p1, p2, problem.meta_data.n_variables, crossover_rate = crossover_rate)\n",
    "        mutated_c1 = mutate(c1, mutation_rate)\n",
    "        mutated_c2 = mutate(c2, mutation_rate)\n",
    "        f1 = problem(mutated_c1)\n",
    "        f2 = problem(mutated_c2)\n",
    "        #print(\"f1\", f1)\n",
    "        #print(\"f2\", f2)\n",
    "        population.append(mutated_c1)\n",
    "        population.append(mutated_c2)\n",
    "    print(\"F1: \", f1)\n",
    "    print(\"F2: \", f2)\n",
    "    return f1, f2 \n",
    "\n",
    "\n",
    "def create_problem(dimension: int, fid: int, name:str) -> Tuple[ioh.problem.PBO, ioh.logger.Analyzer]:\n",
    "    # Declaration of problems to be tested.\n",
    "    problem = get_problem(fid, dimension=dimension, instance=1, problem_class=ProblemClass.PBO)\n",
    "    print(\"creating problem\")\n",
    "    # Create default logger compatible with IOHanalyzer\n",
    "    # `root` indicates where the output files are stored.\n",
    "    # `folder_name` is the name of the folder containing all output. You should compress the folder 'run' and upload it to IOHanalyzer.\n",
    "    l = logger.Analyzer(\n",
    "        root=\"data\",  # the working directory in which a folder named `folder_name` (the next argument) will be created to store data\n",
    "        folder_name=\"run\",  # the folder name to which the raw performance data will be stored\n",
    "        algorithm_name= name,  # name of your algorithm\n",
    "        algorithm_info=\"Practical assignment of the EA course\",\n",
    "    )\n",
    "    # attach the logger to the problem\n",
    "    problem.attach_logger(l)\n",
    "    return problem, l\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "cell_id": "3e4a31749cce4b2b8514c60e39d3b2c1",
    "deepnote_cell_type": "code",
    "execution_context_id": "e7e3c053-c9c8-4c12-ac24-9878d7e18268",
    "execution_millis": 0,
    "execution_start": 1734366700453,
    "source_hash": "f452358"
   },
   "outputs": [],
   "source": [
    "budget = 5000000\n",
    "\n",
    "# To make your results reproducible (not required by the assignment), you could set the random seed by\n",
    "# `np.random.seed(some integer, e.g., 42)`\n",
    "\n",
    "# Hyperparameters to tune, e.g.\n",
    "np.random.seed(42)\n",
    "hyperparameter_space = {\n",
    "    \"population_size\": [50, 100, 200, 500, 1000],\n",
    "    \"mutation_rate\": [0.01, 0.05, 0.1],\n",
    "    \"crossover_rate\": [0.6, 0.8]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "cell_id": "ef7dbfdecac049f88e8ed480aad4aa48",
    "deepnote_cell_type": "code",
    "execution_context_id": "e7e3c053-c9c8-4c12-ac24-9878d7e18268",
    "execution_millis": 0,
    "execution_start": 1734366715073,
    "source_hash": "9025c46e"
   },
   "outputs": [],
   "source": [
    "# Fixed Hyperparameter tuning function with the positional argument issue resolved\n",
    "def tune_hyperparameters() -> List:\n",
    "    # You should decide/engineer the `score` yourself, which is the tuning objective\n",
    "    best_score = float('-inf')\n",
    "    best_params = None\n",
    "    # create the LABS problem and the data logger\n",
    "\n",
    "\n",
    "    for pop_size in hyperparameter_space['population_size']:\n",
    "        for mutation_rate in hyperparameter_space['mutation_rate']:\n",
    "            for crossover_rate in hyperparameter_space['crossover_rate']:\n",
    "\n",
    "                F18, _logger18 = create_problem(dimension=50, fid=18, name=f\"pop_size={pop_size}_mr={mutation_rate}_cr={crossover_rate}\")\n",
    "                # create the N-Queens problem and the data logge\n",
    "                F23, _logger23 = create_problem(dimension=49, fid=23, name=f\"pop_size={pop_size}_mr={mutation_rate}_cr={crossover_rate}\")\n",
    "\n",
    "                \n",
    "                print(\"running hyperparameter tuning for \", pop_size, mutation_rate, crossover_rate)\n",
    "\n",
    "                print(\"Running GA on F18\")\n",
    "                score_f18_1, score_f18_2 = s4018907_s4168216_GA(F18, pop_size, mutation_rate, crossover_rate, budget)\n",
    "                score_f18 = np.mean([score_f18_1, score_f18_2])\n",
    "                print(\"score for F18: \", score_f18)\n",
    "\n",
    "                F18.reset()\n",
    "\n",
    "                if score_f18 > best_score:\n",
    "                    best_score = score_f18\n",
    "                    print(\"best score for F18: \", best_score)\n",
    "                    best_params = [pop_size, mutation_rate, crossover_rate]\n",
    "\n",
    "                print(\"Running GA on F23\")\n",
    "                score_f23_1, score_f23_2 = s4018907_s4168216_GA(F23, pop_size, mutation_rate, crossover_rate, budget)\n",
    "                score_f23 = np.mean([score_f23_1, score_f23_2])\n",
    "                print(\"score for F23: \", score_f23)\n",
    "\n",
    "                F23.reset()\n",
    "\n",
    "                if score_f23 > best_score:\n",
    "                    best_score = score_f23\n",
    "                    print(\"best score for F23: \", best_score)\n",
    "                    best_params = [pop_size, mutation_rate, crossover_rate]\n",
    "\n",
    "    return best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "cell_id": "7cba5a010b14412f820f8e2d56937167",
    "deepnote_cell_type": "code",
    "execution_context_id": "f8991b16-0526-4251-8192-6287b034b130",
    "execution_millis": 1,
    "execution_start": 1734366717111,
    "source_hash": "f7a2605c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n    for mutation_rate in hyperparameter_space['mutation_rate']:\\n    for crossover_rate in hyperparameter_space['crossover_rate']:\\n\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    '''\n",
    "        for mutation_rate in hyperparameter_space['mutation_rate']:\n",
    "        for crossover_rate in hyperparameter_space['crossover_rate']:\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "cell_id": "b287c7473d524b8e9c8da57ca74cb369",
    "deepnote_cell_type": "code",
    "execution_context_id": "e7e3c053-c9c8-4c12-ac24-9878d7e18268",
    "execution_millis": 47507716,
    "execution_start": 1734366754257,
    "source_hash": "afbda785"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating problem\n",
      "creating problem\n",
      "running hyperparameter tuning for  50 0.01 0.6\n",
      "Running GA on F18\n",
      "F1:  0.8350033400133601\n",
      "F2:  1.6960651289009498\n",
      "score for F18:  1.265534234457155\n",
      "best score for F18:  1.265534234457155\n",
      "Running GA on F23\n",
      "F1:  -457.0\n",
      "F2:  -254.0\n",
      "score for F23:  -355.5\n",
      "creating problem\n",
      "creating problem\n",
      "running hyperparameter tuning for  50 0.01 0.8\n",
      "Running GA on F18\n",
      "F1:  1.0548523206751055\n",
      "F2:  0.9881422924901185\n",
      "score for F18:  1.021497306582612\n",
      "Running GA on F23\n",
      "F1:  -336.0\n",
      "F2:  -356.0\n",
      "score for F23:  -346.0\n",
      "creating problem\n",
      "creating problem\n",
      "running hyperparameter tuning for  50 0.05 0.6\n",
      "Running GA on F18\n",
      "F1:  2.1079258010118043\n",
      "F2:  1.2388503468780971\n",
      "score for F18:  1.6733880739449507\n",
      "best score for F18:  1.6733880739449507\n",
      "Running GA on F23\n",
      "F1:  -423.0\n",
      "F2:  -389.0\n",
      "score for F23:  -406.0\n",
      "creating problem\n",
      "creating problem\n",
      "running hyperparameter tuning for  50 0.05 0.8\n",
      "Running GA on F18\n",
      "F1:  1.4863258026159334\n",
      "F2:  1.2388503468780971\n",
      "score for F18:  1.3625880747470154\n",
      "Running GA on F23\n",
      "F1:  -416.0\n",
      "F2:  -510.0\n",
      "score for F23:  -463.0\n",
      "creating problem\n",
      "creating problem\n",
      "running hyperparameter tuning for  50 0.1 0.6\n",
      "Running GA on F18\n",
      "F1:  0.9462528387585163\n",
      "F2:  1.2487512487512487\n",
      "score for F18:  1.0975020437548824\n",
      "Running GA on F23\n",
      "F1:  -295.0\n",
      "F2:  -309.0\n",
      "score for F23:  -302.0\n",
      "creating problem\n",
      "creating problem\n",
      "running hyperparameter tuning for  50 0.1 0.8\n",
      "Running GA on F18\n",
      "F1:  1.2291052114060963\n",
      "F2:  1.0993843447669305\n",
      "score for F18:  1.1642447780865135\n",
      "Running GA on F23\n",
      "F1:  -396.0\n",
      "F2:  -363.0\n",
      "score for F23:  -379.5\n",
      "creating problem\n",
      "creating problem\n",
      "running hyperparameter tuning for  100 0.01 0.6\n",
      "Running GA on F18\n",
      "F1:  1.1563367252543941\n",
      "F2:  1.3116474291710387\n",
      "score for F18:  1.2339920772127164\n",
      "Running GA on F23\n",
      "F1:  -349.0\n",
      "F2:  -322.0\n",
      "score for F23:  -335.5\n",
      "creating problem\n",
      "creating problem\n",
      "running hyperparameter tuning for  100 0.01 0.8\n",
      "Running GA on F18\n",
      "F1:  1.0841283607979184\n",
      "F2:  0.8132726089785296\n",
      "score for F18:  0.948700484888224\n",
      "Running GA on F23\n",
      "F1:  -531.0\n",
      "F2:  -275.0\n",
      "score for F23:  -403.0\n",
      "creating problem\n",
      "creating problem\n",
      "running hyperparameter tuning for  100 0.05 0.6\n",
      "Running GA on F18\n",
      "F1:  1.0548523206751055\n",
      "F2:  0.8486082824168364\n",
      "score for F18:  0.9517303015459709\n",
      "Running GA on F23\n",
      "F1:  -369.0\n",
      "F2:  -430.0\n",
      "score for F23:  -399.5\n",
      "creating problem\n",
      "creating problem\n",
      "running hyperparameter tuning for  100 0.05 0.8\n",
      "Running GA on F18\n",
      "F1:  1.2899896800825594\n",
      "F2:  1.5006002400960383\n",
      "score for F18:  1.395294960089299\n",
      "Running GA on F23\n",
      "F1:  -309.0\n",
      "F2:  -396.0\n",
      "score for F23:  -352.5\n",
      "creating problem\n",
      "creating problem\n",
      "running hyperparameter tuning for  100 0.1 0.6\n",
      "Running GA on F18\n",
      "F1:  1.1825922421948911\n",
      "F2:  0.6222000995520159\n",
      "score for F18:  0.9023961708734536\n",
      "Running GA on F23\n",
      "F1:  -375.0\n",
      "F2:  -342.0\n",
      "score for F23:  -358.5\n",
      "creating problem\n",
      "creating problem\n",
      "running hyperparameter tuning for  100 0.1 0.8\n",
      "Running GA on F18\n",
      "F1:  1.2007684918347743\n",
      "F2:  1.3691128148959475\n",
      "score for F18:  1.284940653365361\n",
      "Running GA on F23\n",
      "F1:  -396.0\n",
      "F2:  -484.0\n",
      "score for F23:  -440.0\n",
      "creating problem\n",
      "creating problem\n",
      "running hyperparameter tuning for  200 0.01 0.6\n",
      "Running GA on F18\n",
      "F1:  0.952018278750952\n",
      "F2:  0.7654623392529087\n",
      "score for F18:  0.8587403090019303\n",
      "Running GA on F23\n",
      "F1:  -322.0\n",
      "F2:  -356.0\n",
      "score for F23:  -339.0\n",
      "creating problem\n",
      "creating problem\n",
      "running hyperparameter tuning for  200 0.01 0.8\n",
      "Running GA on F18\n",
      "F1:  0.821827744904668\n",
      "F2:  1.1071744906997343\n",
      "score for F18:  0.9645011178022012\n",
      "Running GA on F23\n",
      "F1:  -349.0\n",
      "F2:  -335.0\n",
      "score for F23:  -342.0\n",
      "creating problem\n",
      "creating problem\n",
      "running hyperparameter tuning for  200 0.05 0.6\n",
      "Running GA on F18\n",
      "F1:  1.0072522159548751\n",
      "F2:  0.9462528387585163\n",
      "score for F18:  0.9767525273566957\n",
      "Running GA on F23\n",
      "F1:  -309.0\n",
      "F2:  -322.0\n",
      "score for F23:  -315.5\n",
      "creating problem\n",
      "creating problem\n",
      "running hyperparameter tuning for  200 0.05 0.8\n",
      "Running GA on F18\n",
      "F1:  1.1071744906997343\n",
      "F2:  0.9184423218221895\n",
      "score for F18:  1.012808406260962\n",
      "Running GA on F23\n",
      "F1:  -396.0\n",
      "F2:  -410.0\n",
      "score for F23:  -403.0\n",
      "creating problem\n",
      "creating problem\n",
      "running hyperparameter tuning for  200 0.1 0.6\n",
      "Running GA on F18\n",
      "F1:  1.3116474291710387\n",
      "F2:  0.7034327518289252\n",
      "score for F18:  1.0075400904999818\n",
      "Running GA on F23\n",
      "F1:  -295.0\n",
      "F2:  -470.0\n",
      "score for F23:  -382.5\n",
      "creating problem\n",
      "creating problem\n",
      "running hyperparameter tuning for  200 0.1 0.8\n",
      "Running GA on F18\n",
      "F1:  1.2588116817724069\n",
      "F2:  1.3812154696132597\n",
      "score for F18:  1.3200135756928333\n",
      "Running GA on F23\n",
      "F1:  -248.0\n",
      "F2:  -491.0\n",
      "score for F23:  -369.5\n",
      "creating problem\n",
      "creating problem\n",
      "running hyperparameter tuning for  500 0.01 0.6\n",
      "Running GA on F18\n",
      "F1:  0.7617306520414382\n",
      "F2:  1.3007284079084287\n",
      "score for F18:  1.0312295299749334\n",
      "Running GA on F23\n",
      "F1:  -369.0\n",
      "F2:  -490.0\n",
      "score for F23:  -429.5\n",
      "creating problem\n",
      "creating problem\n",
      "running hyperparameter tuning for  500 0.01 0.8\n",
      "Running GA on F18\n",
      "F1:  1.5605493133583022\n",
      "F2:  1.9747235387045814\n",
      "score for F18:  1.7676364260314417\n",
      "best score for F18:  1.7676364260314417\n",
      "Running GA on F23\n",
      "F1:  -436.0\n",
      "F2:  -282.0\n",
      "score for F23:  -359.0\n",
      "creating problem\n",
      "creating problem\n",
      "running hyperparameter tuning for  500 0.05 0.6\n",
      "Running GA on F18\n",
      "F1:  0.9077705156136529\n",
      "F2:  0.952018278750952\n",
      "score for F18:  0.9298943971823024\n",
      "Running GA on F23\n",
      "F1:  -342.0\n",
      "F2:  -396.0\n",
      "score for F23:  -369.0\n",
      "creating problem\n",
      "creating problem\n",
      "running hyperparameter tuning for  500 0.05 0.8\n",
      "Running GA on F18\n",
      "F1:  1.3455328310010763\n",
      "F2:  1.147842056932966\n",
      "score for F18:  1.246687443967021\n",
      "Running GA on F23\n",
      "F1:  -517.0\n",
      "F2:  -349.0\n",
      "score for F23:  -433.0\n",
      "creating problem\n",
      "creating problem\n",
      "running hyperparameter tuning for  500 0.1 0.6\n",
      "Running GA on F18\n",
      "F1:  1.5923566878980893\n",
      "F2:  1.5762925598991173\n",
      "score for F18:  1.5843246238986033\n",
      "Running GA on F23\n",
      "F1:  -369.0\n",
      "F2:  -335.0\n",
      "score for F23:  -352.0\n",
      "creating problem\n",
      "creating problem\n",
      "running hyperparameter tuning for  500 0.1 0.8\n",
      "Running GA on F18\n",
      "F1:  1.1230907457322552\n",
      "F2:  0.7926442612555485\n",
      "score for F18:  0.9578675034939019\n",
      "Running GA on F23\n",
      "F1:  -517.0\n",
      "F2:  -362.0\n",
      "score for F23:  -439.5\n",
      "creating problem\n",
      "creating problem\n",
      "running hyperparameter tuning for  1000 0.01 0.6\n",
      "Running GA on F18\n",
      "F1:  0.994431185361973\n",
      "F2:  1.1916110581506196\n",
      "score for F18:  1.0930211217562964\n",
      "Running GA on F23\n",
      "F1:  -390.0\n",
      "F2:  -282.0\n",
      "score for F23:  -336.0\n",
      "creating problem\n",
      "creating problem\n",
      "running hyperparameter tuning for  1000 0.01 0.8\n",
      "Running GA on F18\n",
      "F1:  1.0271158586688578\n",
      "F2:  0.862663906142167\n",
      "score for F18:  0.9448898824055124\n",
      "Running GA on F23\n",
      "F1:  -254.0\n",
      "F2:  -578.0\n",
      "score for F23:  -416.0\n",
      "creating problem\n",
      "creating problem\n",
      "running hyperparameter tuning for  1000 0.05 0.6\n",
      "Running GA on F18\n",
      "F1:  1.2195121951219512\n",
      "F2:  1.2588116817724069\n",
      "score for F18:  1.239161938447179\n",
      "Running GA on F23\n",
      "F1:  -342.0\n",
      "F2:  -235.0\n",
      "score for F23:  -288.5\n",
      "creating problem\n",
      "creating problem\n",
      "running hyperparameter tuning for  1000 0.05 0.8\n",
      "Running GA on F18\n",
      "F1:  0.5805852299117511\n",
      "F2:  1.1737089201877935\n",
      "score for F18:  0.8771470750497723\n",
      "Running GA on F23\n",
      "F1:  -652.0\n",
      "F2:  -403.0\n",
      "score for F23:  -527.5\n",
      "creating problem\n",
      "creating problem\n",
      "running hyperparameter tuning for  1000 0.1 0.6\n",
      "Running GA on F18\n",
      "F1:  1.3691128148959475\n",
      "F2:  0.7768800497203232\n",
      "score for F18:  1.0729964323081354\n",
      "Running GA on F23\n",
      "F1:  -201.0\n",
      "F2:  -316.0\n",
      "score for F23:  -258.5\n",
      "creating problem\n",
      "creating problem\n",
      "running hyperparameter tuning for  1000 0.1 0.8\n",
      "Running GA on F18\n",
      "F1:  1.0993843447669305\n",
      "F2:  1.625487646293888\n",
      "score for F18:  1.3624359955304093\n",
      "Running GA on F23\n",
      "F1:  -309.0\n",
      "F2:  -416.0\n",
      "score for F23:  -362.5\n",
      "500\n",
      "0.01\n",
      "0.8\n"
     ]
    }
   ],
   "source": [
    "# The error occurs because the function 'tune_hyperparameters' is returning a single object (likely a float or another value),\n",
    "# while the code expects it to return three unpackable values (population_size, mutation_rate, crossover_rate).\n",
    "\n",
    "# Fix: Ensure that the 'tune_hyperparameters' function returns a tuple with 3 values or change the calling code to match\n",
    "# the actual return value of the function.\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # Call the hyperparameter tuning function\n",
    "    best_params = tune_hyperparameters()\n",
    "    #if len(best_params) == 3:\n",
    "    population_size, mutation_rate, crossover_rate = best_params\n",
    "    print(population_size)\n",
    "    print(mutation_rate)\n",
    "    print(crossover_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cell_id": "f06d1c1f0a2e41249cbf86c2d579cba9",
    "deepnote_cell_type": "code",
    "execution_context_id": "df89815a-76c6-4b30-b3ae-b5527525ea44",
    "execution_millis": 1,
    "execution_start": 1734195897322,
    "source_hash": "b4bf3a4f"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'best_params' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mbest_params\u001b[49m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'best_params' is not defined"
     ]
    }
   ],
   "source": [
    "print(best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "304ba53feee74a3885eec07dcb78df88",
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "created_in_deepnote_cell": true,
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=6809d180-5347-4c49-92ff-04f56374e52e' target=\"_blank\">\n",
    "<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\n",
    "Created in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>"
   ]
  }
 ],
 "metadata": {
  "deepnote_full_width": true,
  "deepnote_notebook_id": "631681163e424b0d89179c5aa105716a",
  "deepnote_persisted_session": {
   "createdAt": "2024-12-17T05:45:13.664Z"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
